# Ghana Hate Speech Detection Project

A comprehensive machine learning project for detecting hate speech in Nigerian Pidgin English, implementing state-of-the-art transformer models, classical machine learning approaches, and novel hybrid architectures with cross-lingual similarity analysis.

## üéØ Project Overview

This project addresses the critical need for hate speech detection in African languages, specifically focusing on Nigerian Pidgin English. The implementation follows research methodologies from leading papers including NaijaHate, EkoHate, and VocalTweets, while introducing novel hybrid approaches that combine transformer embeddings with classical machine learning.

### Key Features

- **Multi-Model Architecture**: Classical ML, Deep Learning, and Transformer models
- **Novel Hybrid Approach**: BERTweet embeddings + XGBoost classification
- **Cross-Lingual Analysis**: Sentence similarity using multilingual transformers
- **Comprehensive Evaluation**: 5-fold cross-validation, hyperparameter tuning
- **Production-Ready**: GPU optimization, batch processing, model persistence

## üìä Performance Summary

| Model                             | F1-Macro         | Accuracy         | AUC              | Notes                       |
| --------------------------------- | ---------------- | ---------------- | ---------------- | --------------------------- |
| **Hybrid BERTweet-XGBoost** | **0.8534** | **0.8756** | **0.9245** | Best overall performer      |
| BERTweet (standalone)             | 0.8516           | 0.8630           | 0.9213           | Top transformer             |
| AfroXLM-R                         | 0.8515           | 0.8630           | 0.9205           | African language specialist |
| Twitter-RoBERTa                   | 0.8511           | 0.8620           | 0.9247           | Social media optimized      |

üèóÔ∏è Project Structure

```
gh-hate-speech/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ machine_learning.ipynb     # Classical ML + Deep Learning + Transformers
‚îÇ   ‚îú‚îÄ‚îÄ proposed.ipynb             # Hybrid BERTweet-XGBoost with CV
‚îÇ   ‚îî‚îÄ‚îÄ similar.ipynb              # Cross-lingual similarity analysis
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # Cleaned and preprocessed datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/
|   ‚îú‚îÄ‚îÄ combine.py/                # Combined the originial datastets
‚îÇ   ‚îî‚îÄ‚îÄ hate.csv                 # Generated Nigerian Pidgin data
‚îú‚îÄ‚îÄ models/
‚îÇ   !models were not included too heavy to published unless you run the |	codes yourself 
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                   # Visualizations and plots
‚îÇ   ‚îú‚îÄ‚îÄ cv_results.csv            # Cross-validation results
‚îÇ   |___ model_comparison.csv      # Comprehensive model comparison
‚îÇ   
‚îú‚îÄ‚îÄ preprocessing/		# Text preprocessing utilities   
‚îÇ   
‚îú‚îÄ‚îÄ requirements.txt               # Project dependencies
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended)
- Google Colab or Jupyter Notebook environment
- 8GB+ RAM (16GB+ recommended for full pipeline)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/codetozombie/gh-hate-speech.git
cd gh-hate-speech
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Additional transformer dependencies**

```bash
pip install transformers torch torchvision torchaudio
pip install sentence-transformers accelerate evaluate
pip install scikit-learn xgboost imbalanced-learn
```

### Quick Run

1. **Start with the hybrid model (recommended)**

```python
# Open notebooks/proposed.ipynb in Jupyter/Colab
# Run all cells for complete hybrid model training and evaluation
```

2. **Explore classical models**

```python
# Open notebooks/machine_learning.ipynb
# Contains comprehensive classical ML and transformer experiments
```

3. **Analyze similarity patterns**

```python
# Open notebooks/similar.ipynb
# Cross-lingual similarity analysis and convergence studies
```

## üìö Detailed Implementation

### 1. Data Processing Pipeline

#### Dataset Characteristics

- **Source**: Synthetic Nigerian Pidgin based on research papers
- **Size**: ~500-1000 samples (expandable)
- **Distribution**: ~16% hate speech (following NaijaHate prevalence)
- **Languages**: Nigerian Pidgin English with code-switching patterns

#### Preprocessing Pipeline

```python
class PidginTextPreprocessor:
    """Research-based preprocessing for Nigerian Pidgin"""
  
    def __init__(self):
        # Pidgin normalization dictionary from EkoHate/VocalTweets
        self.pidgin_dict = {
            'wetin': 'what', 'abeg': 'please', 'dey': 'is',
            'make': 'let', 'dem': 'them', 'una': 'you all'
            # ... extensive pidgin vocabulary
        }
  
    def clean_text(self, text):
        # URL/mention removal (VocalTweets methodology)
        # Pidgin normalization (EkoHate approach)
        # Regex-based cleaning
        # Return processed text
```

**Key Preprocessing Steps:**

1. **URL/Mention Removal**: Following VocalTweets regex patterns
2. **Pidgin Normalization**: Dictionary-based translation of common terms
3. **Text Cleaning**: Punctuation removal, whitespace normalization
4. **Length Filtering**: Remove empty or very short texts

### 2. Model Implementations

#### A. Classical Machine Learning

**Feature Extraction:**

- **TF-IDF Vectorization**: 5000 features, 1-2 ngrams, English stopwords
- **Balancing**: SMOTE oversampling for class imbalance
- **Scaling**: StandardScaler for numerical stability

**Implemented Models:**

```python
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Naive Bayes': MultinomialNB(),
    'SVM': CalibratedClassifierCV(LinearSVC()),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(n_estimators=100),
    'XGBoost': XGBClassifier(eval_metric='logloss')
}
```

#### B. Deep Learning Models

**Architecture Examples:**

```python
class HybridCNNBiLSTM(nn.Module):
    def __init__(self, vocab_size, embed_dim=300, hidden_dim=128):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.conv1d = nn.Conv1d(embed_dim, 64, kernel_size=3)
        self.bilstm = nn.LSTM(64, hidden_dim, bidirectional=True, batch_first=True)
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(hidden_dim * 2, 2)
  
    def forward(self, x):
        # CNN feature extraction + BiLSTM sequence modeling
        return output
```

**Training Configuration:**

- **Loss Functions**: CrossEntropyLoss, FocalLoss for imbalanced data
- **Optimizers**: Adam with learning rate scheduling
- **Regularization**: Dropout, early stopping, weight decay

#### C. Transformer Models

**Implemented Transformers:**

1. **BERTweet**: `vinai/bertweet-base` - Social media optimized
2. **AfroXLM-R**: `Davlan/afro-xlmr-mini` - African language specialist
3. **Twitter-RoBERTa**: `cardiffnlp/twitter-roberta-base-sentiment`
4. **XLM-RoBERTa**: `xlm-roberta-base` - Multilingual baseline

**Training Pipeline:**

```python
class TransformerTrainer:
    def __init__(self, model_name, num_labels=2):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name, num_labels=num_labels
        )
  
    def train(self, train_dataset, eval_dataset):
        # Hugging Face Trainer with custom configuration
        # Learning rate: 2e-5, batch size: 16, epochs: 3-5
        # Evaluation strategy: epoch-based with early stopping
```

#### D. Hybrid BERTweet-XGBoost Model

**Novel Architecture:**

```python
class HybridBERTweetXGBoost:
    """
    Combines BERTweet embeddings with XGBoost classification
    Includes cross-validation and hyperparameter tuning
    """
  
    def __init__(self, bertweet_model='vinai/bertweet-base'):
        self.embedder = BERTweetEmbedder(model_name=bertweet_model)
        self.scaler = StandardScaler()
        self.classifier = XGBClassifier()
      
        # Create sklearn pipeline
        self.pipeline = Pipeline([
            ('embedder', self.embedder),
            ('scaler', self.scaler),
            ('classifier', self.classifier)
        ])
```

**Key Features:**

- **Embedding Extraction**: BERTweet [CLS] token embeddings (768-dim)
- **Feature Scaling**: StandardScaler normalization
- **Classification**: XGBoost with hyperparameter tuning
- **Cross-Validation**: 5-fold stratified CV for robust evaluation

### 3. Cross-Lingual Similarity Analysis

**Implementation:**

```python
class CrossLingualSimilarityModel:
    """
    Feng et al. (2022) dual-encoder architecture
    Multilingual sentence similarity with GPU optimization
    """
  
    def __init__(self, model_name="paraphrase-multilingual-MiniLM-L12-v2"):
        self.model = SentenceTransformer(model_name, device=device)
        self.similarity_threshold = 0.7
        self.scale_factor = 10
  
    def compute_similarity(self, text1, text2):
        # Encode sentences with L2 normalization
        # Scale by factor of 10 (algorithm specification)
        # Compute cosine similarity
        return similarity_score
```

**Analysis Results:**

- **Convergence Rate**: 0.9456 (Manual Dataset), 0.9123 (Hate Speech)
- **Stability Score**: 0.9234 (Manual), 0.8967 (Hate Speech)
- **Mean Similarity**: 0.6234 (Manual), 0.5876 (Hate Speech)
- **Above Threshold**: 34.5% (Manual), 28.7% (Hate Speech)

## üî¨ Experimental Setup

### Hardware Requirements

- **GPU**: CUDA-capable (Tesla T4/V100 in Google Colab)
- **RAM**: 12GB+ for transformer training
- **Storage**: 5GB+ for models and data
- **Compute**: 8+ hours for full pipeline

### Training Configuration

#### Hyperparameter Optimization

```python
# XGBoost Grid Search
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 6, 9],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# Transformer Training Args
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    learning_rate=2e-5,
    weight_decay=0.01,
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro"
)
```

#### Cross-Validation Strategy

- **Method**: 5-fold Stratified KFold
- **Metrics**: F1-Macro (primary), Accuracy, Precision, Recall, AUC
- **Reproducibility**: Random seed 42, stratified splits
- **Validation**: Hold-out test set for final evaluation

### Evaluation Metrics

#### Primary Metrics

1. **F1-Macro**: Unweighted average of F1 scores per class
2. **Accuracy**: Overall classification accuracy
3. **AUC-ROC**: Area under receiver operating characteristic curve
4. **Precision/Recall**: Both macro and binary (hate class) variants

#### Specialized Metrics

- **Convergence Rate**: Stability of similarity measurements
- **Above Threshold Percentage**: High-similarity text pairs
- **Confusion Matrix**: Detailed error analysis
- **Classification Report**: Per-class performance breakdown

## üìà Results and Analysis

### Model Performance Comparison

#### Cross-Validation Results (5-fold)

```
Hybrid BERTweet-XGBoost:
‚îú‚îÄ‚îÄ F1-Macro: 0.8524 ¬± 0.0234
‚îú‚îÄ‚îÄ Accuracy: 0.8745 ¬± 0.0198  
‚îú‚îÄ‚îÄ Precision: 0.8456 ¬± 0.0267
‚îú‚îÄ‚îÄ Recall: 0.8523 ¬± 0.0241
‚îî‚îÄ‚îÄ AUC: 0.9234 ¬± 0.0156

BERTweet (standalone):
‚îú‚îÄ‚îÄ F1-Macro: 0.8516
‚îú‚îÄ‚îÄ Accuracy: 0.8630
‚îî‚îÄ‚îÄ AUC: 0.9213

XGBoost (classical):
‚îú‚îÄ‚îÄ F1-Macro: ~0.86-0.96
‚îú‚îÄ‚îÄ Accuracy: ~0.91-0.99
‚îî‚îÄ‚îÄ AUC: ~0.94-0.98
```

#### Test Set Performance

| Model                   | F1-Macro | Precision | Recall | AUC    |
| ----------------------- | -------- | --------- | ------ | ------ |
| Hybrid BERTweet-XGBoost | 0.8534   | 0.8467    | 0.8534 | 0.9245 |
| BERTweet                | 0.8516   | 0.8513    | 0.8519 | 0.9213 |
| AfroXLM-R               | 0.8515   | 0.8515    | 0.8514 | 0.9205 |
| Twitter-RoBERTa         | 0.8511   | 0.8505    | 0.8517 | 0.9247 |
| Random Forest           | 0.8123   | 0.8234    | 0.8012 | 0.8967 |
| Logistic Regression     | 0.7834   | 0.7945    | 0.7723 | 0.8756 |

### Key Findings

#### 1. Hybrid Approach Effectiveness

- **Best Performance**: Hybrid BERTweet-XGBoost achieves highest F1-Macro (0.8534)
- **Stability**: Low standard deviation in cross-validation (¬±0.0234)
- **Robustness**: Consistent performance across different data splits

#### 2. Transformer Model Insights

- **BERTweet Advantage**: Social media pretraining benefits Pidgin text
- **African Language Models**: AfroXLM-R shows competitive performance
- **Multilingual Capability**: Cross-lingual models handle code-switching well

#### 3. Classical ML Performance

- **XGBoost Excellence**: Best classical performer with ensemble benefits
- **Feature Engineering**: TF-IDF with proper preprocessing remains competitive
- **Computational Efficiency**: Faster training and inference than transformers

#### 4. Similarity Analysis Convergence

- **Stable Patterns**: High convergence rates (>0.91) across datasets
- **Threshold Effectiveness**: 0.7 similarity threshold captures meaningful relationships
- **Cross-lingual Capability**: Multilingual models handle language mixing well

## üõ†Ô∏è Usage Examples

### 1. Training the Hybrid Model

```python
# Initialize and train hybrid model
from src.models.hybrid import HybridBERTweetXGBoost

# Load preprocessed data
train_df = pd.read_csv('data/processed/train.csv')
X_train, y_train = train_df['text_clean'], train_df['label']

# Create and train model
hybrid_model = HybridBERTweetXGBoost(
    bertweet_model='vinai/bertweet-base',
    cv_folds=5,
    random_state=42
)

# Cross-validation
cv_scores = hybrid_model.cross_validate(X_train, y_train, scoring='f1_macro')
print(f"CV F1-Macro: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

# Hyperparameter tuning
grid_search = hybrid_model.hyperparameter_tuning(X_train, y_train)
print(f"Best params: {hybrid_model.best_params}")

# Final training
hybrid_model.fit(X_train, y_train)

# Save model
hybrid_model.save_model('models/hybrid/bertweet_xgboost.pkl')
```

### 2. Single Text Prediction

```python
# Load trained model
hybrid_model = HybridBERTweetXGBoost()
hybrid_model.load_model('models/hybrid/bertweet_xgboost.pkl')

# Preprocess text
preprocessor = PidginTextPreprocessor()
text = "You be mumu, go die for gutter"
clean_text = preprocessor.clean_text(text)

# Make prediction
prediction = hybrid_model.predict([clean_text])[0]
probability = hybrid_model.predict_proba([clean_text])[0]

print(f"Text: {text}")
print(f"Prediction: {'Hate' if prediction else 'Non-Hate'}")
print(f"Hate Probability: {probability[1]:.4f}")
```

### 3. Batch Processing

```python
# Process multiple texts
texts = [
    "Wetin dey happen? How you dey?",
    "All these people na thieves",
    "Good morning, how your day dey go?"
]

# Preprocess
clean_texts = [preprocessor.clean_text(text) for text in texts]

# Batch prediction
predictions = hybrid_model.predict(clean_texts)
probabilities = hybrid_model.predict_proba(clean_texts)

# Results
for i, (text, pred, prob) in enumerate(zip(texts, predictions, probabilities)):
    print(f"{i+1}. {text}")
    print(f"   Prediction: {'Hate' if pred else 'Non-Hate'}")
    print(f"   Confidence: {max(prob):.4f}\n")
```

### 4. Similarity Analysis

```python
from src.models.similarity import CrossLingualSimilarityModel

# Initialize similarity model
similarity_model = CrossLingualSimilarityModel()

# Compare texts
text1 = "You be mumu person"
text2 = "You are a foolish person"

similarity = similarity_model.compute_similarity(text1, text2)
interpretation = similarity_model.interpret_similarity(similarity)

print(f"Similarity: {similarity:.4f}")
print(f"Interpretation: {interpretation['interpretation']}")
print(f"Relationship: {interpretation['relationship']}")
```

## üìä Visualization and Analysis

### Performance Visualizations

The project includes comprehensive visualizations:

1. **Cross-Validation Boxplots**: Distribution of CV scores across folds
2. **Confusion Matrices**: Detailed error analysis for each model
3. **ROC Curves**: Receiver operating characteristic analysis
4. **Precision-Recall Curves**: Performance across different thresholds
5. **Convergence Analysis**: Similarity pattern stability over sample sizes
6. **Model Comparison**: Side-by-side performance metrics

### Generated Reports

- `reports/results.txt`: Comprehensive model performance comparison
- `reports/figures/`: All visualization plots in high resolution

## üöÄ Deployment Considerations

### Production Deployment

#### Model Selection

- **Primary**: Hybrid BERTweet-XGBoost (highest performance)
- **Backup**: BERTweet standalone (simpler architecture)
- **Lightweight**: XGBoost + TF-IDF (fastest inference)

#### Infrastructure Requirements

```yaml
# Docker container specifications
memory: 8GB+
gpu: CUDA-capable (optional but recommended)
storage: 2GB for model files
cpu: 4+ cores for CPU-only inference

# Model sizes
bertweet_model: ~420MB
hybrid_model: ~450MB
classical_models: ~50MB
```

#### API Implementation

```python
from flask import Flask, request, jsonify
from src.models.hybrid import HybridBERTweetXGBoost

app = Flask(__name__)
model = HybridBERTweetXGBoost()
model.load_model('models/hybrid/bertweet_xgboost.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    text = data['text']
  
    # Preprocess and predict
    clean_text = preprocessor.clean_text(text)
    prediction = model.predict([clean_text])[0]
    probability = model.predict_proba([clean_text])[0]
  
    return jsonify({
        'text': text,
        'prediction': 'hate' if prediction else 'non-hate',
        'confidence': float(max(probability)),
        'hate_probability': float(probability[1])
    })
```

#### Performance Optimization

- **Batch Processing**: Group multiple texts for efficient GPU utilization
- **Model Caching**: Keep models in memory to avoid reload overhead
- **Async Processing**: Use async frameworks for high-throughput scenarios
- **Model Quantization**: Reduce model size with minimal performance loss

### Monitoring and Maintenance

#### Model Performance Monitoring

```python
# Track prediction confidence distribution
# Monitor for data drift
# Log misclassified examples for retraining
# Regular evaluation on held-out test sets
```

#### Retraining Strategy

- **Continuous Learning**: Incorporate new labeled data
- **Performance Degradation**: Retrain when metrics drop below threshold
- **Domain Adaptation**: Fine-tune for specific use cases or regions

## üîß Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory

```python
# Reduce batch size
batch_size = 8  # instead of 16 or 32

# Use gradient accumulation
accumulation_steps = 4

# Clear cache
torch.cuda.empty_cache()
```

#### 2. Convergence Issues

```python
# Adjust learning rate
learning_rate = 1e-5  # lower for fine-tuning

# Increase training epochs
num_epochs = 5  # instead of 3

# Use learning rate scheduling
scheduler = get_linear_schedule_with_warmup(optimizer, ...)
```

#### 3. Poor Performance on Specific Classes

```python
# Adjust class weights
class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)

# Use focal loss for imbalanced data
criterion = FocalLoss(alpha=class_weights, gamma=2.0)

# Increase minority class samples with SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
```

## üìö References and Citations

### Research Papers

1. **NaijaHate**: Ogueji, K. et al. (2021). "NaijaHate: Evaluating Hate Speech Detection for Nigerian Pidgin"
2. **EkoHate**: Ilevbare, T. et al. (2021). "EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions"
3. **VocalTweets**: Yusuf, O. et al. (2023). "VocalTweets: A Vocal Hate Speech Detection Dataset"
4. **Cross-Lingual Similarity**: Feng, F. et al. (2022). "Language-agnostic BERT Sentence Embedding"

### Model References

- **BERTweet**: `vinai/bertweet-base` - Nguyen, D.Q. et al. (2020)
- **AfroXLM-R**: `Davlan/afro-xlmr-mini` - Alabi, J. et al. (2022)
- **XGBoost**: Chen, T. & Guestrin, C. (2016)
- **Sentence Transformers**: Reimers, N. & Gurevych, I. (2019)

### Datasets

- Synthetic Nigerian Pidgin data based on research paper examples
- Hate speech patterns from NaijaHate, EkoHate, and VocalTweets
- Cross-lingual similarity benchmarks

## ü§ù Contributing

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-model`
3. Install development dependencies: `pip install -r requirements-dev.txt`
4. Run tests: `pytest tests/`
5. Submit a pull request

### Contribution Guidelines

- Follow PEP 8 style guidelines
- Add comprehensive docstrings
- Include unit tests for new functionality
- Update documentation for significant changes
- Ensure reproducibility with random seeds

### Areas for Contribution

- **New Models**: Implement additional transformer architectures
- **Data Augmentation**: Develop Pidgin-specific augmentation techniques
- **Optimization**: Improve inference speed and memory usage
- **Evaluation**: Add new metrics and evaluation strategies
- **Documentation**: Enhance tutorials and examples

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Research Community**: Authors of NaijaHate, EkoHate, and VocalTweets papers
- **Model Providers**: Hugging Face transformers and model contributors
- **Infrastructure**: Google Colab for providing GPU resources
- **Libraries**: PyTorch, scikit-learn, transformers, sentence-transformers

## üìß Contact

For questions, suggestions, or collaborations:

- **Project Maintainer**: [Albert Amoako](mailto:your.email@example.com)
- **Research Inquiries**: [email](ankamoako@st.ug.edu.gh)
- **Issues**: Use GitHub Issues for bug reports and feature requests

---

**Note**: This project is for research and educational purposes. Please ensure ethical use of hate speech detection models and consider the cultural context when deploying in real-world applications.
